{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 12:11:24,120\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-04-19 12:11:24,705\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import random as rand\n",
    "from sklearn import preprocessing, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from controller.pd_controller import PDController\n",
    "from dynamics.linear_system_dynamics import LinearSystemDynamics\n",
    "from dynamics.configuration_dynamics import ConfigurationDynamics\n",
    "\n",
    "from controller.openloop_controller import OpenLoopController\n",
    "from controller.mpc_controller import MPCController\n",
    "from controller.bilinear_fb_lin_controller import BilinearFBLinController\n",
    "from controller.perturbed_controller import PerturbedController\n",
    "from controller.linear_lifted_controller import LinearLiftedController\n",
    "from dynamics.linear_lifted_dynamics import LinearLiftedDynamics\n",
    "from dynamics.bilinear_lifted_dynamics import BilinearLiftedDynamics\n",
    "from learning.edmd import Edmd\n",
    "from learning.bilinear_edmd import BilinearEdmd\n",
    "from basis__functions.planar_quad_basis import PlanarQuadBasis\n",
    "\n",
    "from learning.utils import differentiate_vec\n",
    "\n",
    "from systems.planar_quadrotor_force_input import PlanarQuadrotorForceInput\n",
    "\n",
    "from learning.koop_dnn import KoopDnn \n",
    "from learning.koopman_net_ctrl import KoopmanNetCtrl\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QuadrotorPdOutput(ConfigurationDynamics):\n",
    "    def __init__(self, dynamics, xd, t_d, n, m):\n",
    "        ConfigurationDynamics.__init__(self, dynamics, 1)\n",
    "        self.xd = xd\n",
    "        self.t_d = t_d\n",
    "        self.xd_dot = differentiate_vec(self.xd, self.t_d)\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def proportional(self, x, t):\n",
    "        q, q_dot = x[:int(n/2)], x[int(n/2):]\n",
    "        return self.y(q) - self.y_d(t)\n",
    "\n",
    "    def derivative(self, x, t):\n",
    "        q, q_dot = x[:int(n/2)], x[int(n/2):]\n",
    "        return self.dydq(q)@q_dot - self.y_d_dot(t)\n",
    "\n",
    "    def y(self, q):\n",
    "        return q\n",
    "\n",
    "    def dydq(self, q):\n",
    "        return np.eye(int(self.n/2))\n",
    "\n",
    "    def d2ydq2(self, q):\n",
    "        return np.zeros((int(self.n/2), int(self.n/2), int(self.n/2)))\n",
    "\n",
    "    def y_d(self, t):\n",
    "        return self.desired_state_(t)[:int(self.n/2)]\n",
    "\n",
    "    def y_d_dot(self, t):\n",
    "        return self.desired_state_(t)[int(self.n/2):]\n",
    "\n",
    "    def y_d_ddot(self, t):\n",
    "        return self.desired_state_dot_(t)[int(self.n/2):]\n",
    "\n",
    "    def desired_state_(self, t):\n",
    "        return [np.interp(t, self.t_d.flatten(),self.xd[:,ii].flatten()) for ii in range(self.xd.shape[1])]\n",
    "\n",
    "    def desired_state_dot_(self, t):\n",
    "        return [np.interp(t, self.t_d.flatten(),self.xd_dot[:,ii].flatten()) for ii in range(self.xd_dot.shape[1])]\n",
    "\n",
    "class PlanarQuadrotorForceInputDiscrete(PlanarQuadrotorForceInput):\n",
    "    def __init__(self, mass, inertia, prop_arm, g=9.81, dt=1e-2):\n",
    "        PlanarQuadrotorForceInput.__init__(self, mass, inertia, prop_arm, g=g)\n",
    "        self.dt=dt\n",
    "        \n",
    "    def eval_dot(self, x, u, t):\n",
    "        return x + self.dt*self.drift(x, t) + self.dt*np.dot(self.act(x, t),u)\n",
    "\n",
    "    def get_linearization(self, x0, x1, u0, t):\n",
    "        m, J, b, g = self.params\n",
    "        A_lin = np.eye(self.n) + self.dt*np.array([[0, 0, 0, 1, 0, 0],\n",
    "                                                   [0, 0, 0, 0, 1, 0],\n",
    "                                                   [0, 0, 0, 0, 0, 1],\n",
    "                                                   [0, 0, -(1/m)*np.cos(x0[2])*u0[0] -(1/m)*np.cos(x0[2])*u0[1], 0, 0, 0],\n",
    "                                                   [0, 0, -(1/m)*np.sin(x0[2])*u0[0] -(1/m)*np.sin(x0[2])*u0[1], 0, 0, 0],\n",
    "                                                   [0, 0, 0, 0, 0, 0],])\n",
    "\n",
    "        B_lin = self.dt*np.array([[0, 0],\n",
    "                                  [0, 0],\n",
    "                                  [0, 0],\n",
    "                                  [-(1/m)*np.sin(x0[2]), -(1/m)*np.sin(x0[2])],\n",
    "                                  [(1/m)*np.cos(x0[2]), (1/m)*np.cos(x0[2])],\n",
    "                                  [-b/J, b/J]])\n",
    "\n",
    "        if x1 is None:\n",
    "            x1 = A_lin@x0 + B_lin@u0\n",
    "\n",
    "        f_d = self.eval_dot(x0,u0,t)\n",
    "        r_lin = f_d - x1\n",
    "\n",
    "        return A_lin, B_lin, r_lin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"\n",
    "    Sets up logging to store logs in 'app.log' within a directory specified by the LOG_DIR environment\n",
    "    variable or a default directory if not specified. Each log entry will include a timestamp.\n",
    "    \"\"\"\n",
    "    # Get the log directory from an environment variable or use a default\n",
    "    log_dir = os.getenv('LOG_DIR', os.path.join(os.getcwd(), 'logs'))\n",
    "    os.makedirs(log_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    # Define the path to the log file\n",
    "    log_file_path = os.path.join(log_dir, 'app.log')\n",
    "\n",
    "    # Configure logging to write to the log file with timestamps\n",
    "    logging.basicConfig(\n",
    "        filename=log_file_path,\n",
    "        level=logging.DEBUG,  # Capture all levels of logging\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',  # Include timestamp, level, and message\n",
    "        filemode='a'  # Append to the log file (do not overwrite)\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Planar Quadrotor Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a planar quadrotor with states $\\mathbf{x} = [y \\, z \\, \\theta \\, \\dot{y} \\, \\dot{z} \\, \\dot{\\theta}]^T$ and continuous-time dynamics\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{bmatrix} \\ddot{y} \\\\ \\ddot{z} \\\\ \\ddot{\\theta} \\end{bmatrix}\n",
    "    = \\begin{bmatrix}\n",
    "    0\\\\-g\\\\0\n",
    "    \\end{bmatrix} +\n",
    "    \\begin{bmatrix}\n",
    "    -\\frac{1}{m}\\text{sin}\\theta & -\\frac{1}{m}\\text{sin}\\theta\\\\\n",
    "    \\frac{1}{m}\\text{cos}\\theta & \\frac{1}{m}\\text{cos}\\theta\\\\\n",
    "    -\\frac{l_{arm}}{I_{xx}} & \\frac{l_{arm}}{I_{xx}}\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    T_1 \\\\ T_2\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "where $y,z$ describe the position of the vehicle in a fixed reference frame, $\\theta$ is the orientation of the vehicle,\n",
    "$T_1, T_2$ are the thrust from each of the propellers, $g$ is the gravitational acceleration, $m$ is the vehicle mass,\n",
    "$l_{arm}$ is the distance from the vehicle's center of mass to the center of the propeller, and $I_{xx}$ is the inertia\n",
    "around the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 12:11:36,364 - INFO - PlanarQuadrotorForceInput initialized with m=2.0, J=1.0, b=0.2, g=9.81\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code defines the parameters and linearized system specification for our system.\n",
    "\n",
    "Parameters:\n",
    "- mass: Mass of the cart pole system.\n",
    "- inertia: Inertia of the cart pole system.\n",
    "- prop_arm: Propeller arm length of the quadrotor.\n",
    "- gravity: Acceleration due to gravity.\n",
    "\n",
    "Linearized System Specification:\n",
    "- n: Number of states.\n",
    "- m: Number of control inputs.\n",
    "- A_nom: Linearization of the true system around the origin.\n",
    "- B_nom: Linearization of the true system around the origin.\n",
    "- hover_thrust: Hover thrust of the quadrotor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "mass = 2.\n",
    "inertia = 1.\n",
    "prop_arm = 0.2\n",
    "gravity = 9.81\n",
    "quadrotor = PlanarQuadrotorForceInput(mass, inertia, prop_arm, g=gravity) \n",
    "\n",
    "n, m = 6, 2\n",
    "\n",
    "\n",
    "A_nom = np.array([[0., 0., 0., 1., 0., 0.],\n",
    "                  [0., 0., 0., 0., 1., 0.],\n",
    "                  [0., 0., 0., 0., 0., 1.],\n",
    "                  [0., 0., -gravity, 0., 0., 0.],\n",
    "                  [0., 0., 0., 0., 0., 0.],\n",
    "                  [0., 0., 0., 0., 0., 0.]])\n",
    "B_nom = np.array([[0., 0.],\n",
    "                  [0., 0.],\n",
    "                  [0., 0.],\n",
    "                  [0., 0.],\n",
    "                  [1./mass, 1./mass],\n",
    "                  [-prop_arm/inertia, prop_arm/inertia]])\n",
    "\n",
    "hover_thrust = mass*gravity/m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Collect data for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To collect data, a nominal controller is designed with LQR on the dynamics's linearization around hover. However, any\n",
    "controller can be used and the method does not require the knowledge of model's linearization. In addition, a\n",
    "exploratory white noise is added to the controller to ensure that the data is sufficiently excited. Note that the system\n",
    "is underactuated and that trajectory optimization is necessary to control the position of the vehicle. We use a\n",
    "simplified trajectory generator based on a model predictive controller for the linearized dynamics. More careful design\n",
    "of the desired trajectory may be necessary for more demanding applications and this is readily compatible with our method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 12:11:40,624 - DEBUG - Initializing LinearLiftedDynamics\n",
      "2024-04-19 12:11:40,665 - INFO - LinearLiftedDynamics successfully initialized with continuous model: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#drive.mount(\"/content/drive\", force_remount=True)\n",
    "\n",
    "q_dc, r_dc = 5e2, 1                                                 # State and actuation penalty values, data collection\n",
    "Q_dc = q_dc * np.identity(n)                                        # State penalty matrix, data collection\n",
    "R_dc = r_dc*np.identity(m)                                          # Actuation penalty matrix, data collection\n",
    "P_dc = sc.linalg.solve_continuous_are(A_nom, B_nom, Q_dc, R_dc)     # Algebraic Ricatti equation solution, data collection\n",
    "K_dc = np.linalg.inv(R_dc)@B_nom.T@P_dc                             # LQR feedback gain matrix, data collection\n",
    "K_dc_p = K_dc[:,:int(n/2)]                                          # Proportional control gains, data collection\n",
    "K_dc_d = K_dc[:,int(n/2):]                                          # Derivative control gains, data collection\n",
    "nominal_sys = LinearLiftedDynamics(A_nom, B_nom, np.eye(n), lambda x: x)\n",
    "\n",
    "# Data collection parameters:\n",
    "dt = 1.0e-2                                                         # Time step length\n",
    "traj_length_dc = 2.                                                 # Trajectory length, data collection\n",
    "n_pred_dc = int(traj_length_dc/dt)                                  # Number of time steps, data collection\n",
    "t_eval = dt * np.arange(n_pred_dc + 1)                              # Simulation time points\n",
    "n_traj_train = 200                                                  # Number of trajectories to execute, data collection\n",
    "n_traj_val = int(0.25*n_traj_train)\n",
    "\n",
    "noise_var = 5.                                                      # Exploration noise to perturb controller, data collection\n",
    "\n",
    "xmax = np.array([2, 2, np.pi/3, 2.,2.,2.])                          # State constraints, trajectory generation\n",
    "xmin = -xmax\n",
    "umax = np.array([2*hover_thrust, 2*hover_thrust])                    # Actuation constraint, trajectory generation\n",
    "umin = np.array([0., 0.])\n",
    "x0_max = np.array([xmax[0], xmax[1], xmax[2], 1., 1., 1.])          # Initial value limits\n",
    "Q_trajgen = sc.sparse.diags([0,0,0,0,0,0])                          # State penalty matrix, trajectory generation\n",
    "QN_trajgen = sc.sparse.diags([5e1,5e1,5e1,1e1,1e1,1e1])             # Final state penalty matrix, trajectory generation\n",
    "R_trajgen = sc.sparse.eye(m)                                        # Actuation penalty matrix, trajectory generation\n",
    "sub_sample_rate = 1                                                 # Rate to subsample data for training\n",
    "model_fname = '/Research_data'                         # Path to save learned models\n",
    "n_cols = 10                                                         # Number of columns in training data plot\n",
    "save_figures = True\n",
    "#dropbox_folder = '/Users/carlaxelfolkestad/Dropbox/Apps/Overleaf/Koopman NMPC (ICRA21)/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load('Research_data/training_data.npz')\n",
    "xd = data['xd']\n",
    "xs = data['xs']\n",
    "us = data['us']\n",
    "\n",
    "# Optionally, load the number of training and validation trajectories\n",
    "trajectory_counts = np.load('Research_data/trajectory_counts.npz')\n",
    "n_traj_train = trajectory_counts['n_traj_train']\n",
    "n_traj_val = trajectory_counts['n_traj_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "xs_train = xs[:n_traj_train, :, :]\n",
    "us_train = us[:n_traj_train, :, :]\n",
    "\n",
    "xs_val = xs[n_traj_train:, :, :]\n",
    "us_val = us[n_traj_train:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random as rand\n",
    "\n",
    "# # Pre-allocate arrays for desired state trajectories (xd), actual state trajectories (xs),\n",
    "# # and control inputs (us) for all the training and validation trajectories.\n",
    "# # 'n_traj_train + n_traj_val' is the total number of trajectories (both training and validation).\n",
    "# # 'n_pred_dc + 1' is the prediction horizon plus one for the desired and actual states,\n",
    "# # and 'n' is the number of state variables.\n",
    "# xd = np.empty((n_traj_train + n_traj_val, n_pred_dc + 1, n))\n",
    "# xs = np.empty((n_traj_train + n_traj_val, n_pred_dc + 1, n))\n",
    "\n",
    "# # 'n_pred_dc' is the prediction horizon for the control inputs,\n",
    "# # and 'm' is the number of control inputs.\n",
    "# us = np.empty((n_traj_train + n_traj_val, n_pred_dc, m))\n",
    "\n",
    "# # Set up the figure size for plotting. The size depends on the number of trajectories and the number of columns in the plot.\n",
    "# # The width is fixed at 12 inches, and the height is adjusted to maintain a square for each subplot.\n",
    "# plt.figure(figsize=(12, 12 * (n_traj_train + n_traj_val) / (n_cols ** 2)))\n",
    "\n",
    "# # Loop through the total number of trajectories (training plus validation).\n",
    "# for ii in range(n_traj_train+n_traj_val):\n",
    "#     # Generate a random initial state 'x0' and a random set point 'set_pt_dc' within the specified maximum bounds 'x0_max'.\n",
    "#     x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "#     set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "\n",
    "#     # Initialize the Model Predictive Control (MPC) with the current system, prediction horizon, time step, input and state constraints, and cost matrices.\n",
    "#     mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen, QN_trajgen, set_pt_dc)\n",
    "    \n",
    "#     # Evaluate the MPC to generate a trajectory from the initial state towards the set point.\n",
    "#     mpc_trajgen.eval(x0, 0)\n",
    "    \n",
    "#     # Store the resulting trajectory in 'xd'.\n",
    "#     xd[ii, :, :] = mpc_trajgen.parse_result().T\n",
    "    \n",
    "#     # Validate the initial conditions to ensure they are not too close to the origin or result in NaN values.\n",
    "#     # If not valid, regenerate 'x0' and 'set_pt_dc' and recompute the trajectory.\n",
    "#     while abs(x0[0]) + abs(x0[1]) < 1 or np.any(np.isnan(xd[ii, :, :])):\n",
    "#         x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "#         set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "#         mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin-hover_thrust, umax-hover_thrust, xmin, xmax, QN_trajgen, R_trajgen, QN_trajgen, set_pt_dc)\n",
    "#         mpc_trajgen.eval(x0, 0)\n",
    "#         xd[ii, :, :] = mpc_trajgen.parse_result().T\n",
    "\n",
    "#     # Create an instance of the PD (Proportional-Derivative) output controller using the quadrotor system, \n",
    "#     # the desired trajectory, evaluation times, and state and control dimensions.\n",
    "#     output = QuadrotorPdOutput(quadrotor, xd[ii, :, :], t_eval, n, m)\n",
    "    \n",
    "#     # Initialize the PD controller with the PD output and the proportional and derivative gains.\n",
    "#     pd_controller = PDController(output, K_dc_p, K_dc_d)\n",
    "    \n",
    "#     # Wrap the PD controller with a perturbation controller that introduces noise and a constant offset,\n",
    "#     # simulating real-world disturbances and the need to maintain hover thrust.\n",
    "#     perturbed_pd_controller = PerturbedController(quadrotor, pd_controller, noise_var, const_offset=hover_thrust)\n",
    "    \n",
    "#     # Simulate the quadrotor with the perturbed controller from the initial state over the specified evaluation times.\n",
    "#     # Save the state and control trajectories in 'xs' and 'us', respectively.\n",
    "#     xs[ii, :, :], us[ii, :, :] = quadrotor.simulate(x0, perturbed_pd_controller, t_eval)\n",
    "\n",
    "#     # For each trajectory, create a subplot and plot the actual state components over time in solid lines\n",
    "#     # and the desired state components in dashed lines, using different colors for each state\n",
    "\n",
    "#     plt.plot(t_eval, xs[ii, :, 0], 'b', label='$y$')\n",
    "#     plt.plot(t_eval, xs[ii, :, 1], 'g', label='$z$')\n",
    "#     plt.plot(t_eval, xs[ii, :, 2], 'r', label='$\\\\theta$')\n",
    "#     plt.plot(t_eval, xd[ii, :, 0], '--b', label='$y_d$')\n",
    "#     plt.plot(t_eval, xd[ii, :, 1], '--g', label='$z_d$')\n",
    "#     plt.plot(t_eval, xd[ii, :, 2], '--r', label='$\\\\theta_d$')\n",
    "\n",
    "# plt.suptitle(\n",
    "#     'Training data \\nx-axis: time (sec), y-axis: state value, $x$ - blue, $xd$ - dotted blue, $\\\\theta$ - red, $\\\\theta_d$ - dotted red',\n",
    "#     y=0.94)\n",
    "# plt.show()\n",
    "\n",
    "# xs_train, us_train = xs[:n_traj_train,:,:], us[:n_traj_train, :, :]\n",
    "# xs_val, us_val = xs[n_traj_train:,:,:], us[n_traj_train:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# Assuming xd, xs, and us are already generated\n",
    "\n",
    "# Save xd, xs, and us\n",
    "#np.savez('/content/drive/My Drive/Research/training_data.npz', xd=xd, xs=xs, us=us)\n",
    "\n",
    "# Optionally, save the number of training and validation trajectories\n",
    "#np.savez('/content/drive/My Drive/Research/trajectory_counts.npz', n_traj_train=n_traj_train, n_traj_val=n_traj_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a linear model with dynamic mode decomposition (DMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To compare our method with existing techniques, we first learn a linear state space model from data. This is dubbed\n",
    "dynamic mode decomposition. I.e. we use linear regression with LASSO regularization to learn an approximate linear model\n",
    "with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{x}} = A_{dmd}\\mathbf{x} + B_{dmd}\\mathbf{u}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#DMD parameters:\n",
    "alpha_dmd = 9.8e-5                                                  # Regularization strength (LASSO) DMD\n",
    "tune_mdl_dmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basis = lambda x: x\n",
    "C_dmd = np.eye(n)\n",
    "\n",
    "optimizer_dmd = linear_model.MultiTaskLasso(alpha=alpha_dmd, fit_intercept=False, selection='random') # LASSO regression for DMD optimization \n",
    "cv_dmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random') # Cross-validated LASSO regression for DMD optimization \n",
    "standardizer_dmd = preprocessing.StandardScaler(with_mean=False) # Standardize the data for LASSO regression because it is not scale-invariant \n",
    "\n",
    "# basis is set to lambda x: x, which means we are using the original state as the basis function\n",
    "# n_traj_train is the number of training trajectorie that we have generated in the previous step \n",
    "# optimizer is the LASSO regression model that we are using to fit the DMD model\n",
    "# cv is the cross-validated LASSO regression model that we are using to fit the DMD model\n",
    "# standardizer is the standardization model that we are using to fit the DMD model\n",
    "# C is the identity matrix, which is the linear operator that we are using to fit the DMD model\n",
    "# first_obs_const is set to False, which means that the first observation is not constant\n",
    "# continuous_mdl is set to False, which means that the model is not continuous\n",
    "model_dmd = Edmd(n, m, basis, n, n_traj_train, optimizer_dmd, cv=cv_dmd, standardizer=standardizer_dmd, C=C_dmd, first_obs_const=False, continuous_mdl=False, dt=dt)\n",
    "\n",
    "\n",
    "'''process\n",
    "\n",
    "Prepares input data for dynamic systems modeling by performing the following steps:\n",
    "    \n",
    "    1. Validate Input Shapes: Ensures the input state data x matches expected dimensions.\n",
    "    2. Lift States and Concatenate with Control Inputs: Applies a lift function to state data x \n",
    "       (excluding the last time step) and concatenates the result with control inputs u, forming z_u.\n",
    "    3. Compute Derivatives or Next States:\n",
    "        - If continuous, calculates the derivative of lifted states z over time t.\n",
    "        - If discrete, applies lift to x (starting from the second time step) to get next states.\n",
    "    4. Flatten and Reshape: Transposes and reshapes z_u and derivatives/next states into flat matrices \n",
    "       for analysis, using Fortran-like column-major order.\n",
    "    5. Standardize (Optional): If a standardizer is provided, fits and transforms the data to \n",
    "       standardize feature scales.\n",
    "    6. Downsample: Reduces the data size by selecting every downsample_rate-th data point.\n",
    "    \n",
    "    Returns downsampled and optionally standardized versions of combined lifted states and \n",
    "    control inputs, along with their derivatives or next states, ready for dynamic\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "xdmd, y_dmd = model_dmd.process(xs_train, us_train, np.tile(t_eval,(n_traj_train,1)), downsample_rate=sub_sample_rate)\n",
    "'''\n",
    "        Fits the model to the training data, with options for cross-validation and kinematic override.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features, numpy array of shape (n_samples, n_features).\n",
    "        - y: Target values, numpy array of shape (n_samples, n_targets).\n",
    "        - cv: Perform cross-validation if True. Default is False.\n",
    "        - override_kinematics: If True, kinematic equations are overridden. Default is False.\n",
    "\n",
    "        Steps:\n",
    "        1. Adjust Targets: For discrete models, adjusts target values based on standardization.\n",
    "        2. Override Kinematics: If requested, modifies the target matrix to skip certain dynamics.\n",
    "        3. Cross-Validation: If cv is True, uses the specified cross-validation method to fit the model.\n",
    "        4. Fit Model: Fits the model using the optimizer or cross-validator to find coefficients.\n",
    "        5. Standardize Coefficients: If a standardizer is provided, applies it to the coefficients.\n",
    "        6. Update Model Dynamics: Constructs the A and B matrices from the coefficients, incorporating\n",
    "        any kinematic overrides and ensuring compatibility with the continuous/discrete nature of the model.\n",
    "\n",
    "        Returns:\n",
    "        - None. The function updates the model's internal state with the fitted parameters.\n",
    "        \n",
    "        '''\n",
    "\n",
    "model_dmd.fit(xdmd, y_dmd, cv=tune_mdl_dmd, override_kinematics=True)\n",
    "sys_dmd = LinearLiftedDynamics(model_dmd.A, model_dmd.B, model_dmd.C, model_dmd.basis, continuous_mdl=False, dt=dt)\n",
    "#sys_dmd is the learned DMD model and beig sent \n",
    "if tune_mdl_dmd:\n",
    "    print('$\\\\alpha$ DMD: ',model_dmd.cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a lifted linear model with extended dynamic mode decomposition (EDMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In addition, we compare our method with the current state of the art of Koopman based learning, the extended dynamic mode\n",
    "decomposition. We use a dictionary of nonlinear functions $\\boldsymbol{\\phi(x)}$ to lift the state variables and learn a lifted state space model\n",
    "of the dynamics. I.e. we first lift and then use linear regression with LASSO regularization to learn an approximate\n",
    "lifted linear model with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{z}} = A_{edmd}\\mathbf{z} + B_{edmd}\\mathbf{u}, \\qquad \\mathbf{z} = \\boldsymbol{\\phi(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#EDMD parameters:\n",
    "alpha_edmd = 2.22e-4                                                 # Regularization strength (LASSO) EDMD\n",
    "tune_mdl_edmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "basis = PlanarQuadBasis(n, poly_deg=3)\n",
    "basis.construct_basis()\n",
    "planar_quad_features = preprocessing.FunctionTransformer(basis.basis)\n",
    "planar_quad_features.fit(np.zeros((1,n)))\n",
    "n_lift_edmd = planar_quad_features.transform((np.zeros((1,n)))).shape[1]\n",
    "C_edmd = np.zeros((n,n_lift_edmd))\n",
    "C_edmd[:,1:n+1] = np.eye(n)\n",
    "\n",
    "optimizer_edmd = linear_model.MultiTaskLasso(alpha=alpha_edmd, fit_intercept=False, selection='random', max_iter=2000)\n",
    "cv_edmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random', max_iter=2000)\n",
    "standardizer_edmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "model_edmd = Edmd(n, m, basis.basis, n_lift_edmd, n_traj_train, optimizer_edmd, cv=cv_edmd, standardizer=standardizer_edmd, C=C_edmd, continuous_mdl=False, dt=dt)\n",
    "X_edmd, y_edmd = model_edmd.process(xs_train, us_train, np.tile(t_eval,(n_traj_train,1)), downsample_rate=sub_sample_rate)\n",
    "model_edmd.fit(X_edmd, y_edmd, cv=tune_mdl_edmd, override_kinematics=True)\n",
    "sys_edmd = LinearLiftedDynamics(model_edmd.A, model_edmd.B, model_edmd.C, model_edmd.basis, continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_edmd:\n",
    "    print('$\\\\alpha$ EDMD: ',model_edmd.cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a lifted bilinear model with bilinear extended mode decomposition (bEDMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we use the method developed in the paper to learn a lifted bilinear model of the dynamics, dubbed bilinear\n",
    "extended mode decomposition (bEDMD). I.e. we first lift and then use linear regression with LASSO regularization to learn an approximate\n",
    "lifted linear model with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{z}}=F\\mathbf{z}+\\sum_{i=1}^m G_i\\mathbf{z}\\mathbf{u}_i, \\qquad \\mathbf{z} = \\boldsymbol{\\phi(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Bilinear EDMD parameters:                                           \n",
    "alpha_bedmd = 6.9e-5  # Regularization strength (LASSO) bEDMD\n",
    "tune_mdl_bedmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# n_lift_bedmd = n_lift_edmd\n",
    "# C_bedmd = np.zeros((n,n_lift_bedmd))\n",
    "# C_bedmd[:,1:n+1] = np.eye(n)\n",
    "\n",
    "# basis_bedmd = lambda x: planar_quad_features.transform(x)\n",
    "# optimizer_bedmd = linear_model.MultiTaskLasso(alpha=alpha_bedmd, fit_intercept=False, selection='random', max_iter=10000)\n",
    "# cv_bedmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random')\n",
    "# standardizer_bedmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "# model_bedmd = BilinearEdmd(n, m, basis_bedmd, n_lift_bedmd, n_traj_train, optimizer_bedmd, cv=cv_bedmd, standardizer=standardizer_bedmd, C=C_bedmd, continuous_mdl=False, dt=dt)\n",
    "# X_bedmd, y_bedmd = model_bedmd.process(xs_train, us_train, np.tile(t_eval,(n_traj_train,1)), downsample_rate=sub_sample_rate)\n",
    "# model_bedmd.fit(X_bedmd, y_bedmd, cv=tune_mdl_bedmd, override_kinematics=True)\n",
    "# sys_bedmd = BilinearLiftedDynamics(model_bedmd.n_lift, m, model_bedmd.A, model_bedmd.B, model_bedmd.C, model_bedmd.basis, continuous_mdl=False, dt=dt)\n",
    "# if tune_mdl_bedmd:\n",
    "#     print('$\\\\alpha$ bilinear EDMD: ', model_bedmd.cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "# # Prepare the data to be saved in a dictionary (optional but organized)\n",
    "# save_data = {\n",
    "#     'n_lift_bedmd': n_lift_bedmd,\n",
    "#     'C_bedmd': C_bedmd,\n",
    "#     'basis_bedmd': basis_bedmd,\n",
    "#     'optimizer_bedmd': optimizer_bedmd,\n",
    "#     'cv_bedmd': cv_bedmd,\n",
    "#     'standardizer_bedmd': standardizer_bedmd,\n",
    "#     'model_bedmd': model_bedmd,\n",
    "#     'X_bedmd': X_bedmd,\n",
    "#     'y_bedmd': y_bedmd,\n",
    "#     'sys_bedmd': sys_bedmd,\n",
    "#     'alpha_bedmd': model_bedmd.cv.alpha_ if tune_mdl_bedmd else None,\n",
    "# }\n",
    "\n",
    "# # Specify your save file path\n",
    "# file_path = 'Research_data/bedmd_model_results.dill'\n",
    "\n",
    "# # Use dill to save the data\n",
    "# with open(file_path, 'wb') as outfile:\n",
    "#     dill.dump(save_data, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Research_data/bedmd_model_results.dill'\n",
    "with open(file_path, 'rb') as infile:\n",
    "    loaded_data = dill.load(infile)\n",
    "\n",
    "# Accessing your data\n",
    "basis_bedmd = loaded_data['basis_bedmd']  # This might require special handling if it's a lambda function\n",
    "optimizer_bedmd = loaded_data['optimizer_bedmd']\n",
    "cv_bedmd = loaded_data['cv_bedmd']\n",
    "standardizer_bedmd = loaded_data['standardizer_bedmd']\n",
    "model_bedmd = loaded_data['model_bedmd']\n",
    "X_bedmd = loaded_data['X_bedmd']\n",
    "y_bedmd = loaded_data['y_bedmd']\n",
    "sys_bedmd = loaded_data['sys_bedmd']\n",
    "alpha_bedmd = loaded_data['alpha_bedmd']  # This captures the alpha value if tuning was performed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Koopman bilinear form neural network model (Koop_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dill and torch are available in your environment\n",
    "\n",
    "\n",
    "# Initialize network parameters for a new training session\n",
    "net_params = {\n",
    "    'state_dim': n,  # State dimension\n",
    "    'ctrl_dim': m,  # Control dimension\n",
    "    'encoder_hidden_width': 100,  # Width of hidden layers in the encoder\n",
    "    'encoder_hidden_depth': 4,  # Number of hidden layers in the encoder\n",
    "    'encoder_output_dim': 8,  # Output dimension of the encoder\n",
    "    'optimizer': 'adam',  # Optimizer to use\n",
    "    'activation_type': 'tanh',  # Activation function\n",
    "    'lr': 1e-3,  # Learning rate, consider experimenting with 5e-4 as well\n",
    "    'epochs': 100,  # Number of training epochs for best performance\n",
    "    'batch_size': 128,  # Batch size\n",
    "    'lin_loss_penalty': 0.2,  # Linear loss penalty, best performance so far\n",
    "    'l2_reg': 0.0,  # L2 regularization, best performance so far\n",
    "    'l1_reg': 0.0,  # L1 regularization\n",
    "    'n_fixed_states': 6,  # Number of fixed states\n",
    "    'first_obs_const': True,  # Whether the first observation is constant\n",
    "    'override_kinematics': True,  # Whether to override kinematics\n",
    "    'override_C': True,  # Whether to override the C matrix\n",
    "    'dt': dt,  # Time step for the model\n",
    "}\n",
    "\n",
    "# Print the network parameters to verify configuration\n",
    "print(net_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dill\n",
    "import dill, os, torch\n",
    "\n",
    "load_tuned_params = False\n",
    "\n",
    "if load_tuned_params:\n",
    "    infile = open(os.path.abspath('') + '/data/planar_quad_best_params.pickle', 'rb')\n",
    "    net_params_lst, val_loss, test_loss, open_loop_mse, open_loop_std = dill.load(infile)\n",
    "    infile.close()\n",
    "    net_params = net_params_lst[-3]\n",
    "\n",
    "    print(open_loop_mse)\n",
    "    plt.figure()\n",
    "    plt.plot(val_loss, label='Validation loss')\n",
    "    plt.plot(test_loss, label='Test loss')\n",
    "    plt.plot(open_loop_mse, label='Open loop mse')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    net_params = {}\n",
    "    net_params['state_dim'] = n\n",
    "    net_params['ctrl_dim'] = m\n",
    "    net_params['encoder_hidden_width'] = 100\n",
    "    net_params['encoder_hidden_depth'] = 4\n",
    "    net_params['encoder_output_dim'] = 8\n",
    "    net_params['optimizer'] = 'adam'\n",
    "    net_params['activation_type'] = 'tanh'\n",
    "    net_params['lr'] = 1e-3 # 5e-4\n",
    "    net_params['epochs'] = 100 # Best performance 2000\n",
    "    net_params['batch_size'] = 128\n",
    "    net_params['lin_loss_penalty'] = 0.2 #Best performance until now: 0.2\n",
    "    net_params['l2_reg'] = 0.0          #Best performance until now: 0.0\n",
    "    net_params['l1_reg'] = 0.0\n",
    "    net_params['n_fixed_states'] = 6\n",
    "    net_params['first_obs_const'] = True\n",
    "    net_params['override_kinematics'] = True\n",
    "    net_params['override_C'] = True\n",
    "    net_params['dt'] = dt\n",
    "\n",
    "print(net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_standardizer(data, standardizer, flattened=False):\n",
    "    if flattened:\n",
    "        data_flat = data\n",
    "    else:\n",
    "        n_traj, traj_length, n = data.shape\n",
    "        data_flat = data.T.reshape((n, n_traj * traj_length), order='F').T\n",
    "\n",
    "    standardizer.fit(data_flat)\n",
    "\n",
    "    return standardizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#standardizer_x_kdnn = fit_standardizer(xs_train, preprocessing.StandardScaler())\n",
    "standardizer_u_kdnn = fit_standardizer(us_train, preprocessing.StandardScaler(with_mean=False))\n",
    "\n",
    "#net = KoopmanNetCtrl(net_params, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "net = KoopmanNetCtrl(net_params, standardizer_u=standardizer_u_kdnn)\n",
    "model_koop_dnn = KoopDnn(net)\n",
    "model_koop_dnn.set_datasets(xs_train, np.tile(t_eval,(n_traj_train,1)), u_train=us_train, x_val=xs_val, u_val=us_val, t_val=np.tile(t_eval,(n_traj_val,1)))\n",
    "model_koop_dnn.model_pipeline(net_params)\n",
    "model_koop_dnn.construct_koopman_model()\n",
    "sys_koop_dnn = BilinearLiftedDynamics(model_koop_dnn.net.n_tot, m, model_koop_dnn.A, model_koop_dnn.B, np.array(model_koop_dnn.C, dtype=float), model_koop_dnn.basis_encode,\n",
    "                                    continuous_mdl=False, dt=dt, standardizer_u=standardizer_u_kdnn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# save_path = '/content/drive/My Drive/Research/koop_dnn_model.dill'  # Adjust path as needed\n",
    "\n",
    "# # Bundle everything you want to save into a dictionary\n",
    "# save_data = {\n",
    "#     'net_params': net_params,\n",
    "#     'standardizer_u_kdnn': standardizer_u_kdnn,\n",
    "#     'model_koop_dnn': model_koop_dnn,\n",
    "#     'sys_koop_dnn': sys_koop_dnn,\n",
    "# }\n",
    "\n",
    "# # Use dill to save the data\n",
    "# with open(save_path, 'wb') as outfile:\n",
    "#     dill.dump(save_data, outfile)\n",
    "\n",
    "# print(f'Model and components saved to {save_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# load_path = 'Research_data/koop_dnn_model.dill'  # Adjust path as needed\n",
    "\n",
    "# # Use dill to load the data\n",
    "# with open(load_path, 'rb') as infile:\n",
    "#     loaded_data = dill.load(infile)\n",
    "\n",
    "# # Extract your components\n",
    "# net_params = loaded_data['net_params']\n",
    "# standardizer_u_kdnn = loaded_data['standardizer_u_kdnn']\n",
    "# model_koop_dnn = loaded_data['model_koop_dnn']\n",
    "# sys_koop_dnn = loaded_data['sys_koop_dnn']\n",
    "\n",
    "# print('Model and components loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "train_loss = [l[0] for l in model_koop_dnn.train_loss_hist]\n",
    "train_pred_loss = [l[1] for l in model_koop_dnn.train_loss_hist]\n",
    "train_lin_loss = [l[2] for l in model_koop_dnn.train_loss_hist]\n",
    "val_loss = [l[0] for l in model_koop_dnn.val_loss_hist]\n",
    "val_pred_loss = [l[1] for l in model_koop_dnn.val_loss_hist]\n",
    "val_lin_loss = [l[2] for l in model_koop_dnn.val_loss_hist]\n",
    "epochs = np.arange(0, net_params['epochs'])\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(epochs, train_loss, color='tab:orange', label='Training loss')\n",
    "plt.plot(epochs, train_pred_loss, '--', color='tab:orange', label='Training prediction loss')\n",
    "plt.plot(epochs, train_lin_loss, ':', color='tab:orange', label='Training linear loss')\n",
    "plt.plot(epochs, val_loss, color='tab:blue', label='Validation loss')\n",
    "plt.plot(epochs, val_pred_loss, '--', color='tab:blue', label='Validation prediction loss')\n",
    "plt.plot(epochs, val_lin_loss, ':', color='tab:blue', label='Validation linear loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.savefig('plots/loss_history.png', format='png', dpi=2400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate open loop prediction performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first evaluate the open loop prediction performance of the proposed method.\n",
    "This is done by generating a new data set in the same way as the training set, predicting the evolution of the system\n",
    "with the control sequence of each trajectory executed in the data set with each of the models, and finally comparing\n",
    "the mean and standard deviation of the error between the true and predicted evolution over the trajectories. The\n",
    "experimental results support what is to be expected from the theory as the error in the $y$ and $z$ terms are\n",
    "significantly lower for the bEDMD method than both DMD and EDMD. The reason for this\n",
    "improvement is that the bEDMD method can capture the nonlinearities present in the actuation matrix of the\n",
    "$(y,z)$-dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction performance evaluation parameters:\n",
    "folder_plots = 'working_files/figures/'                                  # Path to save plots\n",
    "n_traj_ol = 100                                                     # Number of trajectories to execute, open loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path for loading from Google Drive with the given filename\n",
    "load_path = 'Research_data/open_loop_prediction_performance.dill'\n",
    "\n",
    "# Deserialize and load data\n",
    "with open(load_path, 'rb') as infile:\n",
    "    loaded_data = dill.load(infile)\n",
    "\n",
    "# Extract loaded data\n",
    "xs_test = loaded_data['xs_test']\n",
    "us_test = loaded_data['us_test']\n",
    "mdl_lst = loaded_data['mdl_lst']  # Ensure custom classes/functions are defined\n",
    "mdl_names = loaded_data['mdl_names']\n",
    "error = loaded_data['error']\n",
    "mse = loaded_data['mse']\n",
    "std = loaded_data['std']\n",
    "\n",
    "print('Data loaded successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from koopman_core.util import evaluate_ol_pred\n",
    "from tabulate import tabulate\n",
    "\n",
    "# xs_test = np.empty((n_traj_ol, t_eval.shape[0], n))\n",
    "# us_test = np.empty((n_traj_ol, t_eval.shape[0]-1, m))\n",
    "\n",
    "# for ii in range(n_traj_ol):\n",
    "#     x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "#     set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "#     mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "#                                 QN_trajgen, set_pt_dc)\n",
    "#     mpc_trajgen.eval(x0, 0)\n",
    "#     xd = mpc_trajgen.parse_result().T\n",
    "\n",
    "#     while xd[0,0] is None:\n",
    "#         x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "#         set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "#         mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin-hover_thrust, umax-hover_thrust, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "#                                     QN_trajgen, set_pt_dc)\n",
    "#         mpc_trajgen.eval(x0, 0)\n",
    "#         xd = mpc_trajgen.parse_result().T\n",
    "\n",
    "#     output = QuadrotorPdOutput(quadrotor, xd, t_eval, n, m)\n",
    "#     pd_controller = PDController(output, K_dc_p, K_dc_d)\n",
    "#     perturbed_pd_controller = PerturbedController(quadrotor, pd_controller, noise_var, const_offset=hover_thrust)\n",
    "\n",
    "#     xs_test[ii,:,:], us_test[ii,:,:] = quadrotor.simulate(x0, perturbed_pd_controller, t_eval)\n",
    "\n",
    "# mdl_lst = [sys_dmd, sys_edmd, sys_bedmd, sys_koop_dnn]\n",
    "# mdl_names = ['DMD', 'EDMD', 'bEDMD', 'Koop DNN']\n",
    "# error, mse, std = [], [], []\n",
    "\n",
    "# for sys in mdl_lst:\n",
    "#     err_tmp, mse_tmp, std_tmp = evaluate_ol_pred(sys, xs_test, np.tile(t_eval,(n_traj_ol,1)), us=us_test)\n",
    "#     error.append(err_tmp)\n",
    "#     mse.append(mse_tmp)\n",
    "#     std.append(std_tmp)\n",
    "\n",
    "# print('\\nOpen loop performance statistics:')\n",
    "# table_data = []\n",
    "# for name, mse_mdl, std_mdl in zip(mdl_names, mse, std):\n",
    "#     table_data.append([name, \"{:.5f}\".format(mse_mdl), \"{:.5f}\".format(std_mdl)])\n",
    "\n",
    "# print(tabulate(table_data, \n",
    "#                headers=['Mean squared error', 'Standard deviation']))\n",
    "print('\\nOpen loop performance statistics:')\n",
    "table_data = []\n",
    "for name, mse_mdl, std_mdl in zip(mdl_names, mse, std):\n",
    "    table_data.append([name, \"{:.5f}\".format(mse_mdl), \"{:.5f}\".format(std_mdl)])\n",
    "\n",
    "print(tabulate(table_data,\n",
    "               headers=['Mean squared error', 'Standard deviation']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# # Bundle data into a dictionary\n",
    "# save_data = {\n",
    "#     'xs_test': xs_test,\n",
    "#     'us_test': us_test,\n",
    "#     'mdl_lst': mdl_lst,  # This may require the models to be serializable\n",
    "#     'mdl_names': mdl_names,\n",
    "#     'error': error,\n",
    "#     'mse': mse,\n",
    "#     'std': std\n",
    "# }\n",
    "\n",
    "# # Define file path for saving in Google Drive with the given filename\n",
    "# save_path = '/content/drive/My Drive/Research/open_loop_prediction_performance.dill'\n",
    "\n",
    "# # Serialize and save data\n",
    "# with open(save_path, 'wb') as outfile:\n",
    "#     dill.dump(save_data, outfile)\n",
    "\n",
    "# print(f'Data saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "figwidth = 16\n",
    "lw = 2\n",
    "fs = 14\n",
    "y_lim_gain = 1.2\n",
    "row = 2\n",
    "\n",
    "\n",
    "# Correct calculation for the number of columns\n",
    "col = math.ceil(n / row)\n",
    "\n",
    "# Plotting open loop results\n",
    "plt.figure(figsize=(figwidth, 4))\n",
    "axs = [plt.subplot(row, col, jj + 1) for jj in range(n)]\n",
    "\n",
    "for ii, err in enumerate(error):\n",
    "    err_mean = np.mean(err, axis=0)\n",
    "    err_std = np.std(err, axis=0)\n",
    "\n",
    "    for jj in range(n):\n",
    "        axs[jj].plot(t_eval[1:], err_mean[:, jj], label=mdl_names[ii])\n",
    "        axs[jj].fill_between(t_eval[1:], err_mean[:, jj] - err_std[:, jj], err_mean[:, jj] + err_std[:, jj], alpha=0.1)\n",
    "\n",
    "for jj in range(n):\n",
    "    axs[jj].set_xlabel('Time (sec)', fontsize=fs)\n",
    "    axs[jj].set_ylabel('$x_' + str(jj + 1) + '$', fontsize=fs)\n",
    "\n",
    "plt.legend(frameon=False, fontsize=fs)\n",
    "stitle = plt.suptitle('Open loop prediction performance of learned models', fontsize=fs + 2)\n",
    "plt.savefig('plots/open_loop_prediction_performance.png', format='png', dpi=2400)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design trajectories based on learned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now study the closed loop performance of the control design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_settings = {}\n",
    "solver_settings['gen_embedded_ctrl'] = False\n",
    "solver_settings['warm_start'] = True\n",
    "solver_settings['polish'] = True\n",
    "solver_settings['polish_refine_iter'] = 3\n",
    "solver_settings['scaling'] = True\n",
    "solver_settings['adaptive_rho'] = False\n",
    "solver_settings['check_termination'] = 25\n",
    "solver_settings['max_iter'] = 4000\n",
    "solver_settings['eps_abs'] = 1e-6\n",
    "solver_settings['eps_rel'] = 1e-6\n",
    "solver_settings['eps_prim_inf'] = 1e-4\n",
    "solver_settings['eps_dual_inf'] = 1e-4\n",
    "solver_settings['linsys_solver'] = 'qdldl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Closed loop performance evaluation parameters:\n",
    "traj_length=250\n",
    "t_eval = dt * np.arange(traj_length+1)                       # Simulation time points, closed loop\n",
    "Q_mpc = sc.sparse.diags([0,0,0,0,0,0])                       # State penalty matrix, trajectory generation\n",
    "QN_mpc = sc.sparse.diags([1e5,1e5,1e5,1e5,1e5,1e5])         # Final state penalty matrix, trajectory generation\n",
    "R_mpc = sc.sparse.eye(m)                                     # Actuation penalty matrix, trajectory generation\n",
    "R0_mpc = sc.sparse.csc_matrix(np.zeros(m))\n",
    "\n",
    "ctrl_offset = np.array([[hover_thrust], [hover_thrust]])\n",
    "\n",
    "# Design trajectory:\n",
    "x0_cl = np.array([-0.8, 0.1, 0.1, -0.3, -0.2, 0.15])                   # Initial value, closed loop trajectory\n",
    "set_pt_cl = np.array([1.9, 1.2, 0., 0., 0., 0.])              # Desired final value, closed loop trajectory\n",
    "xr_cl = np.tile(set_pt_cl.reshape(-1,1), (1, traj_length))\n",
    "xmax = np.array([2, 2, np.pi/3, 2.,2.,2.])                          # State constraints, trajectory generation\n",
    "xmin = -xmax\n",
    "term_constraint=False\n",
    "\n",
    "# Define initial solution for SQP algorithm:\n",
    "x_init = np.linspace(x0_cl, set_pt_cl, int(traj_length)+1)\n",
    "u_init = hover_thrust*np.ones((m,traj_length)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design controllers for learned DMD, EDMD, and bEDMD models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from koopman_core.controllers import MPCController, NonlinearMPCControllerNb, BilinearMPCControllerNb\n",
    "from controller.mpc_controller import MPCController\n",
    "from controller.bilinear_mpc_controller_numba import BilinearMPCControllerNb\n",
    "from controller.nonlinear_mpc_controller_numba import NonlinearMPCControllerNb\n",
    "\n",
    "# Define DMD-based controller:\n",
    "controller_dmd = MPCController(sys_dmd, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint)\n",
    "\n",
    "# Define EDMD-based controller:\n",
    "controller_edmd = MPCController(sys_edmd, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint)\n",
    "\n",
    "# Define bEDMD-based controller:\n",
    "controller_bedmd = BilinearMPCControllerNb(sys_bedmd, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, solver_settings, terminal_constraint=term_constraint)\n",
    "z0_bedmd_cl = sys_bedmd.lift(x0_cl.reshape((1,-1)), None).squeeze()\n",
    "z_init = sys_bedmd.lift(x_init, None)\n",
    "controller_bedmd.construct_controller(z_init, u_init)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define Koop NN controller:\n",
    "controller_koop_dnn = BilinearMPCControllerNb(sys_koop_dnn, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, solver_settings, terminal_constraint=term_constraint)\n",
    "z0_koop_dnn_cl = sys_koop_dnn.lift(x0_cl.reshape((1,-1)), None).squeeze()\n",
    "z_init_koop_dnn = np.array(sys_koop_dnn.lift(x_init, None))\n",
    "controller_koop_dnn.construct_controller(z_init_koop_dnn, u_init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design controller using full knowledge of nonlinear controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrotor_d = PlanarQuadrotorForceInputDiscrete(mass, inertia, prop_arm, g=gravity, dt=dt)\n",
    "controller_nmpc = NonlinearMPCControllerNb(quadrotor_d, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, solver_settings, terminal_constraint=term_constraint)\n",
    "controller_nmpc.construct_controller(x_init, u_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design trajectories with the contructed MPCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "\n",
    "controller_dmd.eval(x0_cl, 0)\n",
    "xr_dmd = controller_dmd.parse_result()\n",
    "ur_dmd = controller_dmd.get_control_prediction()\n",
    "\n",
    "controller_edmd.eval(x0_cl, 0)\n",
    "xr_edmd = sys_edmd.C@controller_edmd.parse_result()\n",
    "ur_edmd = controller_edmd.get_control_prediction()\n",
    "\n",
    "controller_bedmd.solve_to_convergence(z0_bedmd_cl, 0., z_init, u_init, max_iter=max_iter)\n",
    "xr_bedmd = controller_bedmd.get_state_prediction().T\n",
    "ur_bedmd = controller_bedmd.get_control_prediction().T\n",
    "\n",
    "controller_koop_dnn.solve_to_convergence(z0_koop_dnn_cl, 0., z_init_koop_dnn, u_init, max_iter=max_iter)\n",
    "xr_koop_dnn = controller_koop_dnn.get_state_prediction().T\n",
    "ur_koop_dnn = controller_koop_dnn.get_control_prediction().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "controller_nmpc.solve_to_convergence(x0_cl, 0., x_init, u_init, max_iter=max_iter)\n",
    "xr_nmpc = controller_nmpc.get_state_prediction().T\n",
    "ur_nmpc = controller_nmpc.get_control_prediction().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate designed trajectories open loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_controller_dmd = OpenLoopController(quadrotor, ur_dmd.T, t_eval[:-1])\n",
    "xs_dmd, us_dmd = quadrotor.simulate(x0_cl, ol_controller_dmd, t_eval)\n",
    "xs_dmd, us_dmd = xs_dmd.T, us_dmd.T\n",
    "\n",
    "ol_controller_edmd = OpenLoopController(quadrotor, ur_edmd.T, t_eval[:-1])\n",
    "xs_edmd, us_edmd = quadrotor.simulate(x0_cl, ol_controller_edmd, t_eval)\n",
    "xs_edmd, us_edmd = xs_edmd.T, us_edmd.T\n",
    "\n",
    "ol_controller_bedmd = OpenLoopController(quadrotor, ur_bedmd.T, t_eval[:-1])\n",
    "xs_bedmd, us_bedmd = quadrotor.simulate(x0_cl, ol_controller_bedmd, t_eval)\n",
    "xs_bedmd, us_bedmd = xs_bedmd.T, us_bedmd.T\n",
    "\n",
    "ol_controller_koop_dnn = OpenLoopController(quadrotor, ur_koop_dnn.T, t_eval[:-1])\n",
    "xs_koop_dnn, us_koop_dnn = quadrotor.simulate(x0_cl, ol_controller_koop_dnn, t_eval)\n",
    "xs_koop_dnn, us_koop_dnn = xs_koop_dnn.T, us_koop_dnn.T\n",
    "\n",
    "ol_controller_nmpc = OpenLoopController(quadrotor, ur_nmpc.T, t_eval[:-1])\n",
    "xs_nmpc, us_nmpc = quadrotor.simulate(x0_cl, ol_controller_nmpc, t_eval)\n",
    "xs_nmpc, us_nmpc = xs_nmpc.T, us_nmpc.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "plot_inds = [0, 1, 2, 3, 4, 5, 0, 1]\n",
    "subplot_inds = [1, 2, 3, 5, 6, 7, 4, 8]\n",
    "labels = ['$y$ (m)', '$z$ (m)', '$\\\\theta$ (rad)', '$\\\\dot{y}$ (m/s)','$\\\\dot{z}$ (m/s)', '$\\\\dot{\\\\theta}$', '$T_1$ (N)','$T_2$ (N)']\n",
    "titles = ['y-coordinates', 'z-coordinates', '$\\\\theta$-coordinates', 'Control inputs']\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:brown', 'tab:green', 'tab:cyan']\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for ii in range(8):\n",
    "    ind = plot_inds[ii]\n",
    "    if ii < 6:\n",
    "        ax = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval, xr_dmd[ind,:], colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval, xr_edmd[ind, :], colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval, xr_bedmd[ind, :], colors[2], label='bEDMD NMPC')\n",
    "        plt.plot(t_eval, xr_koop_dnn[ind, :], colors[3], label='Koop NN NMPC')\n",
    "        plt.plot(t_eval, xr_nmpc[ind,:], colors[4], label='NMPC')\n",
    "\n",
    "        plt.plot(t_eval, xs_dmd[ind,:], '--', color=colors[0], linewidth=1)\n",
    "        plt.plot(t_eval, xs_edmd[ind, :], '--', color=colors[1], linewidth=1)\n",
    "        plt.plot(t_eval, xs_bedmd[ind, :], '--', color=colors[2], linewidth=1)\n",
    "        plt.plot(t_eval, xs_koop_dnn[ind, :], '--', color=colors[3], linewidth=1)        \n",
    "        plt.plot(t_eval, xs_nmpc[ind,:], '--', color=colors[4], linewidth=1)\n",
    "\n",
    "        plt.scatter(t_eval[0], x0_cl[ind], color='g')\n",
    "        plt.scatter(t_eval[-1], set_pt_cl[ind], color='r')\n",
    "        plt.ylabel(labels[ind])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        if ii >= 3:\n",
    "            plt.plot([0, t_eval[-1]], [xmax[ind], xmax[ind]], ':k')\n",
    "            plt.plot([0, t_eval[-1]], [xmin[ind], xmin[ind]], ':k')\n",
    "        if subplot_inds[ii]==1:\n",
    "            plt.legend(loc='upper left', frameon=False)\n",
    "    elif ii < 8:\n",
    "        ax = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval[:-1],ur_dmd[ind,:], color=colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval[:-1], ur_edmd[ind, :], color=colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval[:-1], ur_bedmd[ind, :], color=colors[2], label='bEDMD NMPC')\n",
    "        plt.plot(t_eval[:-1], ur_koop_dnn[ind, :], color=colors[3], label='Koop NN NMPC')\n",
    "        plt.plot(t_eval[:-1],ur_nmpc[ind,:], color=colors[4], label='NMPC')\n",
    "        plt.plot([0, t_eval[-1]], [umax[ind], umax[ind]], ':k')\n",
    "        plt.plot([0, t_eval[-1]], [umin[ind], umin[ind]], ':k')\n",
    "        plt.ylabel(labels[ii])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        \n",
    "    if subplot_inds[ii] > 4:\n",
    "        plt.xlabel('Time (sec)')\n",
    "    else:\n",
    "        plt.title(titles[subplot_inds[ii]-1])\n",
    "\n",
    "\n",
    "if save_figures:\n",
    "    \n",
    "    plt.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/planar_quad_trajectory.png', format='png', dpi=2400)\n",
    "plt.show()\n",
    "\n",
    "cost_ref_dmd = (xr_dmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_dmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_dmd.T@R_mpc@ur_dmd))\n",
    "cost_ref_edmd = (xr_edmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_edmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_edmd.T@R_mpc@ur_edmd))\n",
    "cost_ref_bedmd = (xr_bedmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_bedmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_bedmd.T@R_mpc@ur_bedmd))\n",
    "cost_ref_koop_dnn = (xr_koop_dnn[:,-1]-set_pt_cl).T@QN_mpc@(xr_koop_dnn[:,-1]-set_pt_cl) + np.sum(np.diag(ur_koop_dnn.T@R_mpc@ur_koop_dnn))\n",
    "cost_ref_nmpc = (xr_nmpc[:,-1]-set_pt_cl).T@QN_mpc@(xr_nmpc[:,-1]-set_pt_cl) + np.sum(np.diag(ur_nmpc.T@R_mpc@ur_nmpc))\n",
    "\n",
    "dist_ol_dmd = np.linalg.norm(xs_dmd[:,-1] - set_pt_cl)\n",
    "dist_ol_edmd = np.linalg.norm(xs_edmd[:,-1] - set_pt_cl)\n",
    "dist_ol_bedmd = np.linalg.norm(xs_bedmd[:,-1] - set_pt_cl)\n",
    "dist_ol_koop_dnn = np.linalg.norm(xs_koop_dnn[:,-1] - set_pt_cl)\n",
    "dist_ol_nmpc = np.linalg.norm(xs_nmpc[:,-1] - set_pt_cl)\n",
    "\n",
    "print('Solution statistics:\\n')\n",
    "print(tabulate([['DMD MPC', \"{:.4f}\".format(cost_ref_dmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_dmd), '-','-',sum(controller_dmd.comp_time)], \n",
    "                ['EDMD MPC', \"{:.4f}\".format(cost_ref_edmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_edmd),'-','-',sum(controller_edmd.comp_time)], \n",
    "                ['bEDMD NMPC', \"{:.4f}\".format(cost_ref_bedmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_bedmd), len(controller_bedmd.x_iter), \"{:.4f}\".format(np.mean(controller_bedmd.comp_time)), sum(controller_bedmd.comp_time)],\n",
    "                ['Koop NN NMPC', \"{:.4f}\".format(cost_ref_koop_dnn/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_koop_dnn), len(controller_koop_dnn.x_iter), \"{:.4f}\".format(np.mean(controller_koop_dnn.comp_time)), sum(controller_koop_dnn.comp_time)],\n",
    "                ['NMPC (benchmark)', 1, \"{:.4f}\".format(dist_ol_nmpc), len(controller_nmpc.x_iter), \"{:.4f}\".format(np.mean(controller_nmpc.comp_time)), sum(controller_nmpc.comp_time)]], \n",
    "               headers=['Normalized cost,\\ndesigned trajectory', 'Realized terminal,\\nerror', '# of SQP\\niterations','Mean comp. time\\nper iteration (secs)', 'Total comp.\\ntime (secs)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study evolution of the solution after each iteration of the SQP-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = min(len(controller_nmpc.x_iter),len(controller_bedmd.x_iter))\n",
    "\n",
    "# Calculate cost after each iteration:\n",
    "iter_cost_bedmd, iter_cost_nmpc = [], []\n",
    "\n",
    "ol_controller_init = OpenLoopController(quadrotor, u_init, t_eval[:-1])\n",
    "xs_init, _ = quadrotor.simulate(x0_cl, ol_controller_init, t_eval)\n",
    "xs_init, us_init = xs_init.T, u_init.T\n",
    "init_cost = (xs_init[:,-1]-set_pt_cl).T@QN_mpc@(xs_init[:,-1]-set_pt_cl) + np.sum(np.diag(us_init.T@R_mpc@us_init))\n",
    "iter_cost_bedmd = [init_cost]\n",
    "iter_cost_koop_dnn = [init_cost]\n",
    "iter_cost_nmpc = [init_cost]\n",
    "iter_norm_dist_bedmd = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "iter_norm_dist_koop_dnn = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "iter_norm_dist_nmpc = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "\n",
    "for ii in range(len(controller_bedmd.x_iter)):\n",
    "    ur_bedmd_iter = controller_bedmd.u_iter[ii].T\n",
    "    ol_controller_bedmd_iter = OpenLoopController(quadrotor, ur_bedmd_iter, t_eval[:-1])\n",
    "    xs_bedmd_iter, _ = quadrotor.simulate(x0_cl, ol_controller_bedmd_iter, t_eval)\n",
    "    xs_bedmd_iter, us_bedmd_iter = xs_bedmd_iter.T, ur_bedmd_iter.T\n",
    "    iter_cost_bedmd.append((xs_bedmd_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_bedmd_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_bedmd_iter.T@R_mpc@us_bedmd_iter)))\n",
    "    iter_norm_dist_bedmd.append(np.linalg.norm(xs_bedmd_iter[:,-1]-set_pt_cl))\n",
    "\n",
    "for ii in range(len(controller_bedmd.x_iter)):\n",
    "    ur_koop_dnn_iter = controller_koop_dnn.u_iter[ii].T\n",
    "    ol_controller_koop_dnn_iter = OpenLoopController(quadrotor, ur_koop_dnn_iter, t_eval[:-1])\n",
    "    xs_koop_dnn_iter, _ = quadrotor.simulate(x0_cl, ol_controller_koop_dnn_iter, t_eval)\n",
    "    xs_koop_dnn_iter, us_koop_dnn_iter = xs_koop_dnn_iter.T, ur_koop_dnn_iter.T\n",
    "    iter_cost_koop_dnn.append((xs_koop_dnn_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_koop_dnn_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_koop_dnn_iter.T@R_mpc@us_koop_dnn_iter)))\n",
    "    iter_norm_dist_koop_dnn.append(np.linalg.norm(xs_koop_dnn_iter[:,-1]-set_pt_cl))\n",
    "\n",
    "for ii in range(len(controller_nmpc.x_iter)):\n",
    "    ur_nmpc_iter = controller_nmpc.u_iter[ii].T\n",
    "    ol_controller_nmpc_iter = OpenLoopController(quadrotor, ur_nmpc_iter, t_eval[:-1])\n",
    "    xs_nmpc_iter, _ = quadrotor.simulate(x0_cl, ol_controller_nmpc_iter, t_eval)\n",
    "    xs_nmpc_iter, us_nmpc_iter = xs_nmpc_iter.T, ur_nmpc_iter.T\n",
    "    iter_cost_nmpc.append((xs_nmpc_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_nmpc_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_nmpc_iter.T@R_mpc@us_nmpc_iter)))\n",
    "    iter_norm_dist_nmpc.append(np.linalg.norm(xs_nmpc_iter[:,-1]-set_pt_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.suptitle('Control solution after each iteration of the SQP-algorithm for NMPC and K-NMPC')\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.arange(n_iter), iter_cost_bedmd[:n_iter]/iter_cost_nmpc[-1], color=colors[2], label='bEDMD NMPC')\n",
    "plt.plot(np.arange(n_iter), iter_cost_koop_dnn[:n_iter]/iter_cost_nmpc[-1], color=colors[3], label='Koop NN NMPC')\n",
    "plt.plot(np.arange(n_iter), iter_cost_nmpc[:n_iter]/iter_cost_nmpc[-1], color=colors[4], label='NMPC')\n",
    "plt.ylim(0,5)\n",
    "plt.title('Control effort')\n",
    "plt.ylabel('$||u||$')\n",
    "plt.legend(loc='upper right', frameon=False)\n",
    "plt.xlabel('SQP iteration')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_bedmd[:n_iter], color=colors[2])\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_koop_dnn[:n_iter], color=colors[3])\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_nmpc[:n_iter], color=colors[4])\n",
    "plt.ylim(0,5)\n",
    "plt.title('Realized terminal distance from setpoint')\n",
    "plt.ylabel('$||x_N - x_d||$')\n",
    "plt.xlabel('SQP iteration')\n",
    "\n",
    "if save_figures:\n",
    "    \n",
    "    plt.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/planar_quad_sqp_iterations.png', format='png', dpi=2400)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Solution statistics\\n')\n",
    "print(tabulate([['Nonlinear MPC', len(controller_nmpc.x_iter), np.mean(controller_nmpc.comp_time), np.std(controller_nmpc.comp_time), sum(controller_nmpc.comp_time)],\n",
    "                ['Koopman bilinear MPC', len(controller_bedmd.x_iter), np.mean(controller_bedmd.comp_time), np.std(controller_bedmd.comp_time), sum(controller_bedmd.comp_time)]], \n",
    "               headers=['Number of SQP\\niterations','Mean comp. time per\\niteration (secs)', 'Std comp. time per\\niteration (secs)', 'Total comp.\\ntime (secs)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performance of controllers for closed-loop control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design finite horizon controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from controller.perturbed_controller import PerturbedController\n",
    "\n",
    "Q_mpc_cl = sc.sparse.diags([1e3, 1e3, 1e3, 1e2, 1e2, 1e2])\n",
    "QN_mpc_cl = Q_mpc_cl\n",
    "R_mpc_cl = sc.sparse.eye(m)\n",
    "traj_duration = 0.5\n",
    "N_cl = int(traj_duration/dt)\n",
    "t_eval_cl=np.arange(250)*dt\n",
    "\n",
    "solver_settings_cl = solver_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_dmd_cl = MPCController(sys_dmd, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_dmd_cl = PerturbedController(sys_dmd,controller_dmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "\n",
    "controller_edmd_cl = MPCController(sys_edmd, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_edmd_cl = PerturbedController(sys_edmd,controller_edmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "\n",
    "controller_bedmd_cl = BilinearMPCControllerNb(sys_bedmd, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, solver_settings_cl, add_slack=True)\n",
    "controller_bedmd_cl.construct_controller(controller_bedmd.cur_z[:N_cl+1,:], controller_bedmd.cur_u[:N_cl,:])\n",
    "controller_bedmd_cl.solve_to_convergence(z0_bedmd_cl, 0., controller_bedmd.cur_z[:N_cl+1,:], controller_bedmd.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "_ = controller_bedmd_cl.eval(x0_cl, 0.)\n",
    "controller_bedmd_cl = PerturbedController(sys_bedmd,controller_bedmd_cl,0., umin=umin, umax=umax)\n",
    "\n",
    "\n",
    "controller_koop_dnn_cl = BilinearMPCControllerNb(sys_koop_dnn, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, solver_settings_cl, add_slack=True)\n",
    "controller_koop_dnn_cl.construct_controller(controller_koop_dnn.cur_z[:N_cl+1,:], controller_koop_dnn.cur_u[:N_cl,:])\n",
    "controller_koop_dnn_cl.solve_to_convergence(z0_koop_dnn_cl, 0., controller_koop_dnn.cur_z[:N_cl+1,:], controller_koop_dnn.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "_ = controller_koop_dnn_cl.eval(x0_cl, 0.)\n",
    "controller_koop_dnn_cl = PerturbedController(sys_koop_dnn,controller_koop_dnn_cl,0.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "controller_nmpc_cl = NonlinearMPCControllerNb(quadrotor_d, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, solver_settings_cl, add_slack=True)\n",
    "controller_nmpc_cl.construct_controller(controller_nmpc.cur_z[:N_cl+1,:], controller_nmpc.cur_u[:N_cl,:])\n",
    "controller_nmpc_cl.solve_to_convergence(x0_cl, 0., controller_nmpc.cur_z[:N_cl+1,:], controller_nmpc.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "_ = controller_nmpc_cl.eval(x0_cl, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_bedmd_cl.nom_controller.comp_time, controller_bedmd_cl.nom_controller.prep_time, controller_bedmd_cl.nom_controller.qp_time,  = [], [], []\n",
    "controller_koop_dnn_cl.nom_controller.comp_time, controller_koop_dnn_cl.nom_controller.prep_time, controller_koop_dnn_cl.nom_controller.qp_time,  = [], [], []\n",
    "controller_nmpc_cl.comp_time, controller_nmpc_cl.prep_time, controller_nmpc_cl.qp_time,  = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_settings_cl['polish'] = False\n",
    "solver_settings_cl['check_termination'] = 10\n",
    "solver_settings_cl['max_iter'] = 10\n",
    "solver_settings_cl['eps_abs'] = 1e-2\n",
    "solver_settings_cl['eps_rel'] = 1e-2\n",
    "solver_settings['eps_prim_inf'] = 1e-3\n",
    "solver_settings['eps_dual_inf'] = 1e-3\n",
    "\n",
    "controller_nmpc_cl.update_solver_settings(solver_settings_cl)\n",
    "controller_koop_dnn_cl.nom_controller.update_solver_settings(solver_settings_cl)\n",
    "controller_bedmd_cl.nom_controller.update_solver_settings(solver_settings_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate designed trajectories closed-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_dmd_cl, us_dmd_cl = quadrotor.simulate(x0_cl, controller_dmd_cl, t_eval_cl)\n",
    "xs_dmd_cl, us_dmd_cl = xs_dmd_cl.T, us_dmd_cl.T\n",
    "\n",
    "xs_edmd_cl, us_edmd_cl = quadrotor.simulate(x0_cl, controller_edmd_cl, t_eval_cl)\n",
    "xs_edmd_cl, us_edmd_cl = xs_edmd_cl.T, us_edmd_cl.T\n",
    "\n",
    "controller_bedmd_cl.comp_time = []\n",
    "xs_bedmd_cl, us_bedmd_cl = quadrotor.simulate(x0_cl, controller_bedmd_cl, t_eval_cl)\n",
    "xs_bedmd_cl, us_bedmd_cl = xs_bedmd_cl.T, us_bedmd_cl.T\n",
    "\n",
    "\n",
    "controller_koop_dnn_cl.comp_time = []\n",
    "xs_koop_dnn_cl, us_koop_dnn_cl = quadrotor.simulate(x0_cl, controller_koop_dnn_cl, t_eval_cl)\n",
    "xs_koop_dnn_cl, us_koop_dnn_cl = xs_koop_dnn_cl.T, us_koop_dnn_cl.T\n",
    "\n",
    "\n",
    "controller_nmpc_cl.comp_time = []\n",
    "xs_nmpc_cl, us_nmpc_cl = quadrotor.simulate(x0_cl, controller_nmpc_cl, t_eval_cl)\n",
    "xs_nmpc_cl, us_nmpc_cl = xs_nmpc_cl.T, us_nmpc_cl.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot/analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inds = [0, 1, 2, 0, 1]\n",
    "subplot_inds = [1, 2, 3, 4, 8]\n",
    "\n",
    "plt.figure(figsize=(12,2.5))\n",
    "for ii in range(5):\n",
    "    ind = plot_inds[ii]\n",
    "    if ii < 3:\n",
    "        ax = plt.subplot(1,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval_cl, xs_dmd_cl[ind,:], colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval_cl, xs_edmd_cl[ind, :], colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval_cl, xs_bedmd_cl[ind, :], colors[2], label='bEDMD NMPC')\n",
    "        plt.plot(t_eval_cl, xs_koop_dnn_cl[ind, :], colors[3], label='Koop NN NMPC')\n",
    "        plt.plot(t_eval_cl, xs_nmpc_cl[ind,:], colors[4], label='NMPC')\n",
    "\n",
    "        plt.scatter(t_eval_cl[0], x0_cl[ind], color='g')\n",
    "        plt.scatter(t_eval_cl[-1], set_pt_cl[ind], color='r')\n",
    "        plt.ylabel(labels[ind])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.title(titles[subplot_inds[ii]-1])\n",
    "        plt.xlabel('Time (sec)')\n",
    "        if subplot_inds[ii]==1:\n",
    "            plt.legend(loc='upper left', frameon=False)\n",
    "    else:\n",
    "        bx = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval_cl[:-1],us_dmd_cl[ind,:], color=colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_edmd_cl[ind, :], color=colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_bedmd_cl[ind, :], color=colors[2], label='bEDMD NMPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_koop_dnn_cl[ind, :], color=colors[3], label='Koop NN NMPC')\n",
    "        plt.plot(t_eval_cl[:-1],us_nmpc_cl[ind,:], color=colors[4], label='NMPC')\n",
    "        plt.plot([0, t_eval_cl[-1]], [umax[ind], umax[ind]], ':k')\n",
    "        plt.plot([0, t_eval_cl[-1]], [umin[ind], umin[ind]], ':k')\n",
    "        plt.ylabel(labels[ii+3])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        if subplot_inds[ii] == 4:\n",
    "            plt.title('Control inputs')\n",
    "        else:\n",
    "            plt.xlabel('Time (sec)')\n",
    "if save_figures:\n",
    "    plt.rcParams['png.fonttype'] = 42\n",
    "    plt.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/planar_quad_closed_loop.png', format='png', dpi=2400)\n",
    "plt.show()\n",
    "    \n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "from scipy import ndimage\n",
    "\n",
    "draw_inds = np.arange(0,t_eval_cl.size)[::50]\n",
    "\n",
    "plt.figure(figsize=(12,2))\n",
    "ax = plt.subplot(1,1,1, frameon=False)\n",
    "plt.plot(xs_bedmd_cl[0,:], xs_bedmd_cl[1,:], color=colors[2], label='Koopman NMPC closed loop trajectory with quadrotor orientation sampled at 2 hz')\n",
    "plt.xlabel('y (m)')\n",
    "plt.ylabel('z (m)')\n",
    "plt.legend(loc='upper left',frameon=False)\n",
    "for ii in draw_inds:\n",
    "    im_quad = plt.imread('plots/quad_figure_rb.png')\n",
    "    im_quad = ndimage.rotate(im_quad, xs_bedmd_cl[2,ii]*180)\n",
    "    imagebox_quad = OffsetImage(im_quad, zoom=.11)\n",
    "    ab = AnnotationBbox(imagebox_quad, [xs_bedmd_cl[0,ii], xs_bedmd_cl[1,ii]], frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "if save_figures:\n",
    "    plt.rcParams['png.fonttype'] = 42\n",
    "    plt.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/planar_quad_closed_loop_2.png', format='png', dpi=2400)\n",
    "plt.show()\n",
    "\n",
    "cost_cl_dmd = np.sum(np.diag((xs_dmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_dmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_dmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_dmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_dmd_cl.T@R_mpc_cl@us_dmd_cl))\n",
    "cost_cl_edmd = np.sum(np.diag((xs_edmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_edmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_edmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_edmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_edmd_cl.T@R_mpc_cl@us_edmd_cl))\n",
    "cost_cl_bedmd = np.sum(np.diag((xs_bedmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_bedmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_bedmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_bedmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_bedmd_cl.T@R_mpc_cl@us_bedmd_cl))\n",
    "cost_cl_koop_dnn = np.sum(np.diag((xs_koop_dnn_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_koop_dnn_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_koop_dnn_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_koop_dnn_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_koop_dnn_cl.T@R_mpc_cl@us_koop_dnn_cl))\n",
    "cost_cl_nmpc = np.sum(np.diag((xs_nmpc_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_nmpc_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_nmpc_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_nmpc_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_nmpc_cl.T@R_mpc_cl@us_nmpc_cl))\n",
    "\n",
    "print('Solution statistics:\\n')\n",
    "print(tabulate([['DMD MPC', \"{:.4f}\".format(cost_cl_dmd/cost_cl_nmpc), np.mean(controller_dmd_cl.nom_controller.comp_time), np.std(controller_dmd_cl.nom_controller.comp_time)], \n",
    "                ['EDMD MPC', \"{:.4f}\".format(cost_cl_edmd/cost_cl_nmpc),np.mean(controller_edmd_cl.nom_controller.comp_time), np.std(controller_edmd_cl.nom_controller.comp_time)], \n",
    "                ['bEDMD NMPC', \"{:.4f}\".format(cost_cl_bedmd/cost_cl_nmpc), np.mean(controller_bedmd_cl.nom_controller.comp_time), np.std(controller_bedmd_cl.nom_controller.comp_time)],\n",
    "                ['Koop NN NMPC', \"{:.4f}\".format(cost_cl_koop_dnn/cost_cl_nmpc), np.mean(controller_koop_dnn_cl.nom_controller.comp_time), np.std(controller_koop_dnn_cl.nom_controller.comp_time)],\n",
    "                ['NMPC (benchmark, known model)',1, np.mean(controller_nmpc_cl.comp_time), np.std(controller_nmpc_cl.comp_time)]], \n",
    "               headers=['Normalized cost,\\nrealized trajectory', 'Mean comp. time (secs)', 'std comp. time (secs)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSolution time profiling:\\n')\n",
    "print(tabulate([['NMPC', np.mean(controller_nmpc_cl.comp_time), np.mean(controller_nmpc_cl.prep_time), np.mean(controller_nmpc_cl.qp_time)],\n",
    "                ['Koop NN NMPC', np.mean(controller_koop_dnn_cl.nom_controller.comp_time), np.mean(controller_koop_dnn_cl.nom_controller.prep_time), np.mean(controller_koop_dnn_cl.nom_controller.qp_time)],\n",
    "                ['bEDMD NMPC', np.mean(controller_bedmd_cl.nom_controller.comp_time), np.mean(controller_bedmd_cl.nom_controller.prep_time), np.mean(controller_bedmd_cl.nom_controller.qp_time)]],\n",
    "               headers=['Total comp time', 'setup time', 'qp solve time' ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
